{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACES P3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## default config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aces.environement.p3.aces_p3 import ACES_p3\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "from aces.environement.p3.config_class import AcesArguments,LLMArguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/flowers/work/hf/Qwen3-4B'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "port = 30050\n",
    "req= f\"http://localhost:{port}/v1/models\"\n",
    "response = requests.get(\n",
    "    req,\n",
    "    headers={\"Authorization\": \"Bearer None\"},)\n",
    "response.json()[\"data\"][0][\"id\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send 1 / 1 messages\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m cfg_generation[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_body\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_template_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menable_thinking\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}})\n\u001b[1;32m     12\u001b[0m batch_prompt \u001b[38;5;241m=\u001b[39m [[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhat is the capital of France?\u001b[39m\u001b[38;5;124m\"\u001b[39m}]]\n\u001b[0;32m---> 13\u001b[0m \u001b[43mget_multiple_completions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg_generation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/aces/aces/llm_client.py:349\u001b[0m, in \u001b[0;36mget_multiple_completions\u001b[0;34m(client, batch_prompt, cfg_generation, max_workers, temperature, n)\u001b[0m\n\u001b[1;32m    347\u001b[0m completions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    348\u001b[0m count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 349\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_workers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msub_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msub_batch\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/aces/lib/python3.11/concurrent/futures/_base.py:647\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 647\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/aces/lib/python3.11/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/aces/lib/python3.11/threading.py:1119\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1119\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/aces/lib/python3.11/threading.py:1139\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1140\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from openai import OpenAI, AzureOpenAI\n",
    "from aces.llm_client import get_multiple_completions\n",
    "\n",
    "port = 30062\n",
    "model_name_or_path = \"/home/flowers/work/hf/Qwen3-4B\"\n",
    "base_url=f\"http://localhost:{port}/v1\"  #f\"http://localhost:{port}/v1\" \n",
    "client = OpenAI(base_url=base_url, api_key=\"None\")\n",
    "cfg_generation = {\"model\": model_name_or_path, \"temperature\": 0.6,\"max_tokens\": 10000}\n",
    "if not \"extra_body\" in cfg_generation:\n",
    "    cfg_generation[\"extra_body\"] = {}\n",
    "cfg_generation[\"extra_body\"].update({\"chat_template_kwargs\":{\"enable_thinking\": False}})\n",
    "batch_prompt = [[{\"role\": \"user\", \"content\": \"what is the capital of France?\"}]]\n",
    "get_multiple_completions(client,batch_prompt, cfg_generation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': '/home/flowers/work/hf/Qwen3-4B',\n",
       " 'temperature': 0.6,\n",
       " 'max_tokens': 10000,\n",
       " 'extra_body': {'chat_template_kwargs': {'enable_thinking': False}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using closed source model API (e.g OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from key import api_key # import your api key from a file called key.py in the same directory as this script\n",
    "model_name_or_path = \"gpt-4.1\" #choose your model https://platform.openai.com/docs/models/gp\n",
    "path_save = \"/home/flowers/work/aces/save_data/\" # path to save the archive\n",
    "path_checkpoint_archive = \"/home/flowers/work/aces/save_data/aces_P3_gpt41_0/generation_39.pkl\"#\"/home/flowers/work/aces/save_data/aces_P3_expe_0/generation_7.pkl\" # \"if != '' resume experiment from the given a archive checkpoint \"\n",
    "name_experience = \"aces_P3_gpt41\" # name of the experience\n",
    "api_key = api_key # your api key\n",
    "base_url = \"https://petunia-julien.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview\" # let that empty (\"\") if you don't self-host an OpenAI compatible server\n",
    "aces_args = AcesArguments(path_save=path_save, name_experience=name_experience,path_checkpoint_archive=path_checkpoint_archive) \n",
    "llm_args = LLMArguments(model_name_or_path=model_name_or_path,api_key=api_key,base_url=base_url)\n",
    "print(\"args:\")\n",
    "print(aces_args)\n",
    "print(llm_args)\n",
    "aces= ACES_p3(aces_args, llm_args)\n",
    "aces.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "path_archive = \"/home/flowers/work/aces/save_data/aces_P3_gpt41_0/generation_21.pkl\"\n",
    "with open(path_archive, \"rb\") as f:\n",
    "    archive  = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(650,704):\n",
    "#     if archive[i].fitness > -0.5:\n",
    "        \n",
    "#         print(archive[i].description)\n",
    "#         print(archive[i].fitness)\n",
    "#         print(archive[i].program_str)\n",
    "#         print(\"--\"*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aces",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
